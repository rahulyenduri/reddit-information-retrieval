{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b3656",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ac485",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da217251",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd84429",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install networkx==3.1\n",
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace765b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f47c17f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.38.2\n",
      "2.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bead043",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4647459345544e61a7c81c61365cba40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\UCR_Projects\\RLProject\\RLenv\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Soheil\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-small-en-v1.5') # you can change the model here\n",
    "model = AutoModel.from_pretrained('BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad79398-f976-414c-bdb7-de73d438bac1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792515c2-d7b2-4fb1-9f8a-9916c39b77e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 384])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54247cef-7126-4ad9-977f-3c10ef63c797",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3095,  0.6000,  0.1314,  ..., -0.4734,  0.0277,  0.0955],\n",
       "         [-0.0089,  0.1133, -0.0657,  ..., -0.3988,  0.3408,  0.4774],\n",
       "         [-0.1598,  0.9341,  0.3608,  ..., -0.4125,  0.3438,  0.2293],\n",
       "         ...,\n",
       "         [-0.3095,  0.6000,  0.1314,  ..., -0.4735,  0.0277,  0.0955],\n",
       "         [-0.3095,  0.6000,  0.1314,  ..., -0.4735,  0.0277,  0.0955],\n",
       "         [-0.3095,  0.6000,  0.1314,  ..., -0.4735,  0.0277,  0.0955]],\n",
       "\n",
       "        [[-0.2455, -0.3795,  0.4676,  ...,  0.6978,  0.1150,  0.0131],\n",
       "         [-0.4006, -0.0357,  0.3751,  ...,  0.4017,  0.5057,  0.4307],\n",
       "         [-0.4496, -0.3925,  0.3116,  ...,  0.4118,  0.8414, -0.0073],\n",
       "         ...,\n",
       "         [-0.2455, -0.3795,  0.4676,  ...,  0.6977,  0.1150,  0.0131],\n",
       "         [-0.2455, -0.3795,  0.4676,  ...,  0.6978,  0.1150,  0.0131],\n",
       "         [-0.2454, -0.3796,  0.4677,  ...,  0.6977,  0.1149,  0.0130]],\n",
       "\n",
       "        [[-0.1163,  0.4797,  0.0555,  ..., -0.2075, -0.3212, -0.1198],\n",
       "         [-0.1758,  0.6830, -0.0600,  ..., -0.1480, -0.0143,  0.0873],\n",
       "         [-0.2073,  0.5229,  0.0841,  ..., -0.0474, -0.3418, -0.0121],\n",
       "         ...,\n",
       "         [-0.1163,  0.4798,  0.0556,  ..., -0.2075, -0.3214, -0.1198],\n",
       "         [-0.1163,  0.4797,  0.0556,  ..., -0.2075, -0.3213, -0.1198],\n",
       "         [-0.1163,  0.4798,  0.0556,  ..., -0.2075, -0.3213, -0.1198]],\n",
       "\n",
       "        [[-0.2169, -0.2828, -0.1407,  ..., -0.1947,  0.1219,  0.4508],\n",
       "         [-0.2776, -0.0295, -0.2218,  ..., -0.4859,  0.0246,  0.4635],\n",
       "         [-0.4011, -0.1805,  0.0943,  ..., -0.3787,  0.4549,  0.6531],\n",
       "         ...,\n",
       "         [-0.2169, -0.2828, -0.1407,  ..., -0.1947,  0.1219,  0.4508],\n",
       "         [-0.2169, -0.2828, -0.1407,  ..., -0.1947,  0.1218,  0.4508],\n",
       "         [-0.2169, -0.2828, -0.1407,  ..., -0.1947,  0.1219,  0.4508]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43705851-8ced-4c91-ad61-398ee603800d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After we have produced our dense vectors embeddings, we need to perform a mean pooling operation to create a single vector encoding (the sentence embedding). To do this mean pooling operation, we will need to multiply each value in our embeddings tensor by its respective attention_mask value â€” so that we ignore non-real tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62c4382-fc9e-47b7-ace9-90876fc565f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize our attention_mask tensor:\n",
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b491e3d8-4d22-4e08-a2bf-8d00e3f472d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 384])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c94166-8bb7-44b3-8f14-39b9f832b131",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Each vector above represents a single token attention mask - each token now has a vector of size 768 representing it's attention_mask status. Then we multiply the two tensors to apply the attention mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f214908-d7bf-48aa-a434-800858a5d46e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 384])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embeddings = embeddings * mask\n",
    "masked_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4c604-715f-420f-9fdb-2ac9459a2023",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\"Mean Pooling\" starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6802dde8-032f-4525-bd7b-6d6d1bbc2536",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then we sum the remained of the embeddings along axis 1, because we want to reduce the 512 tokens to 1 dimension\n",
    "summed = torch.sum(masked_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9057ad-35f2-48ea-8f65-ab825161377e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "we want to count only those values that we want to give attention\n",
    "then divide by the sum to get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2875ec78-3d6a-4334-ac3a-de18ab6bb23b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clamp returns the same tensor with a range given, clamp is used to replace the zeros to a very minimal value\n",
    "# to avoid divide by zero error\n",
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f27de-eee2-4ced-95dd-8d1c84d73bf6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we calculate the mean as the sum of the embedding activations summed divided by the number of values that should be given attention in each position `summed_mask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d68564e3-c7e9-4008-84a6-e07eeeb451f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_pooled = summed / summed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88430bd-b04a-41d9-a8c6-040389ac4d00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`mean_pooled` is the final \"dense representation\" of the sentences, note that mean_pooled contains all representations for all sentences together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "626ff959-9c31-4568-aa62-53a971153065",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2187,  0.5695,  0.2394,  ..., -0.4227,  0.2383,  0.1496],\n",
       "        [-0.3022, -0.2839,  0.4135,  ...,  0.5210,  0.2369,  0.0987],\n",
       "        [-0.1402,  0.4530,  0.0868,  ..., -0.2211, -0.2011, -0.1606],\n",
       "        [-0.2279, -0.2567, -0.0771,  ..., -0.3134,  0.2999,  0.3894]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8d3e2-cb93-4966-85c8-52c0e3443a96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8e292d6-21f2-4250-881a-4bb9652ce67c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_embedding(query):\n",
    "    tokens = {'input_ids': [], 'attention_mask': []}\n",
    "    new_tokens = tokenizer.encode_plus(query, max_length=512,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "    tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "    tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    masked_embeddings = embeddings * mask\n",
    "    summed = torch.sum(masked_embeddings, 1)\n",
    "    summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    mean_pooled = summed / summed_mask\n",
    "    \n",
    "    return mean_pooled[0] # assuming query is a single sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1eb20a7-b6aa-419a-9126-adaffa54a191",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb96482-d2c3-4d3b-8732-767683bf8614",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"Nemo is a fish\"\n",
    "query_embedding = convert_to_embedding(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0f95da6-71d0-47dd-886a-b9ed601e5c7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 384])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a5033c-e6cf-46a8-9653-0d29b0562795",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4140, 0.5127, 0.3851, 0.4938])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity()\n",
    "sim = cos(query_embedding, mean_pooled)\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850408bb-8d7c-4f96-9388-d119407938f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb7c08e3-270f-443c-81b7-85c67ee2dc94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfaiss\u001B[39;00m                   \u001B[38;5;66;03m# make faiss available\u001B[39;00m\n\u001B[0;32m      2\u001B[0m index \u001B[38;5;241m=\u001B[39m faiss\u001B[38;5;241m.\u001B[39mIndexFlatIP(\u001B[38;5;241m384\u001B[39m)   \u001B[38;5;66;03m# build the index\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(index\u001B[38;5;241m.\u001B[39mis_trained)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "import faiss                   # make faiss available\n",
    "index = faiss.IndexFlatIP(384)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(mean_pooled)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3be0a8c4-61b4-4801-92d7-63cbf6657675",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d793c9cb-27eb-4505-9e1c-41d85592bd3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed57aaed-351a-48d4-bef5-62a39a61834e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "D, I = index.search(query_embedding[None, :], 1) # None dimension is added because we only have one query against 4 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6da8a1b8-c0ab-4568-b100-1150addcf9f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.04268]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6d5efcf-c042-4d43-af51-027d9c158fce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a94e449-cbd6-4bc8-898c-8b07da14dd33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "faiss.write_index(index,\"sample_code.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28123327-d986-493d-a413-b6ed621f4407",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_loaded = faiss.read_index(\"sample_code.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2fe74a9-69c6-47db-a271-1da7d0989615",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "D, I = index_loaded.search(query_embedding[None, :], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32287a19-0e0a-4e72-8042-8f1bf431c989",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.04268 , 26.346306, 17.326878, 14.138208]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b7b7b2f-ab4a-4f26-84a6-417c51951300",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 0, 2]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d667e30-e0be-44a1-b970-260d23f47bf8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}